# -*- coding: utf-8 -*-
"""Bangalore_housing_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D_6zR4CgxvLhs24469HoS0vQlWpkwtwv
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
# %matplotlib inline
import matplotlib
matplotlib.rcParams["figure.figsize"]=(20,10)

from google.colab import files
uploaded = files.upload()

df = pd.read_csv('Bengaluru_House_Data.csv')
df.head()

df.shape

df.groupby('area_type')['area_type'].agg('count')

df1=df.drop(['area_type','society','balcony','availability'],axis='columns')
df1.head()

df1.isnull().sum()

df3=df1.dropna()
df3.isnull().sum()

"""df3.shape

df3['size'].unique()
"""

df3['size'].unique()

df3['bhk']=df3['size'].apply(lambda x: int(x.split(' ')[0]))

df3

df3.total_sqft.unique()

def is_float(x):
  try:
    float(x)
  except:
      return False
  return True

df3[~df3['total_sqft'].apply(is_float)].head(10)

df4=df3.copy()
df4

def covert_sqft_to_num(x):
    if isinstance(x, str):
        tokens = x.split('-')
        if len(tokens) == 2:
            return (float(tokens[0]) + float(tokens[1])) / 2
        try:
            return float(x)
        except ValueError:
            return None
    elif isinstance(x, float):
        return x
    else:
        return None

df4['total_sqft'] = df4['total_sqft'].apply(covert_sqft_to_num)

df4.head()

df4.loc[30]

df5=df4.copy()
df5['price_per_sqft'] =df5['price']*100000/df5['total_sqft']
df5.head()

df5.location =df5.location.apply(lambda x : x.strip())
# location_stats =df5.groupby('location')['location'].agg('count') gives the count in order to find the values in descending i used sort_Values(ascending=False)
location_stats =df5.groupby('location')['location'].agg('count').sort_values(ascending=False)
location_stats

len(location_stats[location_stats <=10])
# to find the number of non repetition below 10

location_stats_less_than_10 = location_stats[location_stats <=10]
location_stats_less_than_10

len(df5.location.unique())

df5.location = df5.location.apply(lambda x: 'other' if x in location_stats_less_than_10 else x  )
len(df5.location.unique())

df5.head()

df5[df5.total_sqft/df5.bhk<300].head()

df6=df5[~(df5.total_sqft/df5.bhk<300)]
df6.shape

df6.price_per_sqft.describe()

def remove_pps_outliers(df):
  df_out = pd.DataFrame()
  for key, subdf in df.groupby('location'):
     m = np.mean(subdf.price_per_sqft)
     st=np.std(subdf.price_per_sqft)
     reduced_df =subdf[(subdf.price_per_sqft > (m-st)) & (subdf.price_per_sqft <=(m+st))]
     df_out = pd.concat([df_out, reduced_df],ignore_index=True)
  return df_out

df7 = remove_pps_outliers(df6)
df7.shape

def plot_scatter_chart(df, location):
    bhk2 = df[(df.location == location) & (df.bhk == 2)]
    bhk3 = df[(df.location == location) & (df.bhk == 3)]

    matplotlib.rcParams['figure.figsize'] = (15, 10)

    plt.scatter(bhk2.total_sqft, bhk2.price_per_sqft, color='blue', label='2 BHK', s=50)
    plt.scatter(bhk3.total_sqft, bhk3.price_per_sqft, marker='+', color='green', label='3 BHK', s=50)

    plt.xlabel('Total Square Feet Area')
    plt.ylabel('Price Per Square Feet')
    plt.title(location)
    plt.legend()

plot_scatter_chart(df7, 'Rajaji Nagar')

# there are lots of anomolies likenp
# 2 bhk rooms priced below   1 bhk room price

def remove_bhk_outliers(df):
  exclude_indices =np.array([])
  for location ,location_df in df.groupby('location'):
      bhk_stats = {}
      for bhk , bhk_df in location_df.groupby('bhk'):
        bhk_stats[bhk] = {
            'mean' : np.mean(bhk_df.price_per_sqft),
            'std' : np.std(bhk_df.price_per_sqft),
            'count' : bhk_df.shape[0]
        }
      for bhk, bhk_df in location_df.groupby('bhk'):
        stats = bhk_stats.get(bhk-1)
        if stats and stats['count']>5:
          exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft <(stats['mean']) ].index.values)
  return df.drop(exclude_indices,axis='index')





df8 =  remove_bhk_outliers(df7)
df8.shape

plot_scatter_chart(df7,'Hebbal')

df8.bath.unique()

df8[df8.bath>10]

plt.hist(df8.bath,rwidth=0.8)
plt.xlabel('number of bathrooms')
plt.ylabel('count')

df9 = df8[df8.bath<df8.bhk+2]
df9.shape



df10=df9.drop(['size','price_per_sqft'],axis='columns')
df10.head()

dummies = pd.get_dummies(df10.location)
dummies.head(3)

df11=pd.concat ([df10,dummies.drop('other',axis='columns')],axis='columns')
# drop the last column here the last column is other .. we do this so that to minimize the code in the in the table
df11.head(3)

df11.shape

df12 =df11.drop('location',axis='columns')
df12.head()

df12.shape

x= df12.drop('price',axis='columns')

x.head()

y= df12.price
y.head()

from sklearn.model_selection import train_test_split
x_train, x_test , y_train , y_test = train_test_split(x,y,test_size=0.2,random_state=10)

from sklearn.linear_model import LinearRegression
lr_clf= LinearRegression()
lr_clf.fit(x_train,y_train)
lr_clf.score(x_test,y_test)

from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import cross_val_score

cv = ShuffleSplit(n_splits=5, test_size =0.2, random_state=0)

cross_val_score(LinearRegression(),x,y,cv=cv)

from sklearn.model_selection import GridSearchCV, ShuffleSplit
from sklearn.linear_model import LinearRegression, Lasso
from sklearn.tree import DecisionTreeRegressor


def find_best_model_using_gridsearchcv(x, y):
    algos = {
        'linear_regression': {
            'model': LinearRegression(),
            'params': {
                # 'normalize': [True, False]

            }
        },
        'lasso': {
            'model': Lasso(),
            'params': {
                'alpha': [1, 2],
                'selection': ['random', 'cyclic']
            }
        },
        'decision_tree': {
            'model': DecisionTreeRegressor(),
            'params': {
                'criterion': ['mse', 'friedman_mse'],
                'splitter': ['best', 'random']
            }
        }
    }

    scores = []
    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)

    for algo_name, config in algos.items():
        gs = GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)
        gs.fit(x, y)
        scores.append({
            'model': algo_name,
            'best_score': gs.best_score_,
            'best_params': gs.best_params_
        })

    return pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])


# Corrected function call
find_best_model_using_gridsearchcv(x, y)

x.columns

def predict_price(location,sqft,bath,bhk ):
  loc_index = np.where(x.columns == location)[0]

  X = np.zeros(len(x.columns))
  X[0] = sqft
  X[1] = bath
  X[2] = bhk
  if loc_index >= 0:
    X[loc_index] = 1

  return lr_clf.predict([X])[0]




predict_price('st Phase JP Nagar',1000,3,3)

import pickle
with open('Bangalore_housing_data.pickle','wb') as f:
  pickle.dump(lr_clf,f)

import json
columns = {
    'data_columns' : [col.lower() for col in x.columns]
}
with open('col')